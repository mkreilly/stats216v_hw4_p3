---
title: "R Notebook"
output: html_notebook
---
## Problem 3


This problem involves the OJ data set which is part of the ISLR package.
(a) Create a training set containing a random sample of 535 observations, and a test set containing the remaining observations. Use the commands set.seed(2017); train = sample(1:nrow(OJ), 535); test = setdiff(1:nrow(OJ), train).
(b) Fit a (linear) support vector classifier to the training data using cost=1, with Purchase as the response and the other variables as predictors. Use the summary() function to produce summary statistics about the SVM, and describe the results obtained.
(c) What are the training and test error rates?
(d) Use the tune() function to select an optimal cost. Consider values in the range
0.01 to 10.
(e) Compute the training and test error rates using this new value for cost.
(f) Repeat parts (b) through (e) using a support vector machine with a radial kernel. Use the default value for gamma.
(g) Repeat parts (b) through (e) using a support vector machine with a polynomial kernel of degree 2.
(h) Repeat parts (b) through (e) using a linear support vector machine, applied to an expanded feature set consisting of linear and all possible quadratic terms for the predictors. How does this compare to the polynomial kernel both conceptually and in terms of the results for this problem?
(i) Overall, which approach seems to give the best results on this data?